# Deep-Learning-Specialization
deep learning specialization on  coursera by deeplearning.ai
<img align="right" src="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/deep%20learning%20logo.jpg"/>

# Course 1: Neural Networks and Deep Learning

## Week 1: Introduction to deep learning

- Welcome
- What is a neural network?
- Supervised Learning with Neural Networks
- Why is Deep Learning taking off?
- Geoffrey Hinton interview

## Week 2:Neural Networks Basics
Learn to set up a machine learning problem with a neural network mindset. Learn to use vectorization to speed up your models.

- Binary Classification
- Logistic Regression
- Logistic Regression Cost Function
- Gradient Descent
- Derivatives,More Derivative Examples
- Computation graph ,Derivatives with a Computation Graph
- Logistic Regression Gradient Descent
- Gradient Descent on m Examples
- Vectorization, More Vectorization Examples6m
- Vectorizing Logistic Regression
- Vectorizing Logistic Regression's Gradient Output
- Broadcasting in Python
- A note on python/numpy vectors
- Explanation of logistic regression cost function 
- Pieter Abbeel interview
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/1.%20Neural%20Networks%20and%20Deep%20Learning/w2-Logisitc%20Regression%20as%20Neural%20Network/Logistic_Regression_with_a_Neural_Network_mindset_v6a.ipynb"> Logistic Regression with a Neural Network mindset</a>

## Week 3:Shallow neural networks
Learn to build a neural network with one hidden layer, using forward propagation and backpropagation.

- Neural Networks Overview, Neural Network Representation
- Computing a Neural Network's Output
- Vectorizing across multiple examples
- Activation functions
- Why do you need non-linear activation functions? ,Derivatives of activation functions
- Gradient descent for Neural Networks
- Backpropagation intuition
- Random Initialization
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/1.%20Neural%20Networks%20and%20Deep%20Learning/w3-Planar%20data%20classfication%20with%20one%20hidden%20layer/Planar_data_classification_with_onehidden_layer_v6c.ipynb">Planar data classification with one hidden layer</a>

## Week 4 :Deep Neural Networks
Understand the key computations underlying deep learning, use them to build and train deep neural networks, and apply it to computer vision.

- Deep L-layer neural network
- Forward Propagation in a Deep Network
- Getting your matrix dimensions right
- Why deep representations?
- Building blocks of deep neural networks
- Forward and Backward Propagation
- Parameters vs Hyperparameters
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/1.%20Neural%20Networks%20and%20Deep%20Learning/w4-Build%20your%20Deep%20Neural%20Network%20step%20by%20step/Building_your_Deep_Neural_Network_Step_by_Step_v8a.ipynb">Building your Deep Neural Network: Step by Step</a>
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/1.%20Neural%20Networks%20and%20Deep%20Learning/w4-Deep%20NN%20application%20(Image%20Classification)/Deep%2BNeural%2BNetwork%2B-%2BApplication%2Bv8.ipynb">Deep Neural Network for Image Classification: Application</a>

# Course 2: Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization

## Week 1: Practical aspects of Deep Learning

- Train / Dev / Test sets
- Bias / Variance
- Basic Recipe for Machine Learning
- Regularization
- Why regularization reduces overfitting?
- Dropout Regularization
- Understanding Dropout
- Other regularization methods
- Normalizing inputs
- Vanishing / Exploding gradients
- Weight Initialization for Deep Networks
- Numerical approximation of gradients
- Gradient checking
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/2.%20Improving%20deep%20Neural%20Networks(Hyperparameter%20tuning%2CRegularization%20and%20Optimization)/w1-Gradient%20Checking/Gradient%2BChecking%2Bv1.ipynb">Gradient Checking  from scratch </a>
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/2.%20Improving%20deep%20Neural%20Networks(Hyperparameter%20tuning%2CRegularization%20and%20Optimization)/w1-Initialization/Initialization.ipynb"> Initialization (different types) of Neural Network from scratch </a>
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/2.%20Improving%20deep%20Neural%20Networks(Hyperparameter%20tuning%2CRegularization%20and%20Optimization)/w1-Regularization/Regularization_v2a.ipynb"> 
Regularization different types) of Neural Network from scratch</a>

## Week 2:Optimization algorithms

- Mini-batch gradient descent
- Understanding mini-batch gradient descent
- Exponentially weighted averages
- Understanding exponentially weighted averages
- Bias correction in exponentially weighted averages
- Gradient descent with momentum
- RMSprop
- Adam optimization algorithm
- Learning rate decay
- The problem of local optima
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/2.%20Improving%20deep%20Neural%20Networks(Hyperparameter%20tuning%2CRegularization%20and%20Optimization)/w2-Optimization/Optimization_methods_v1b.ipynb"> 
Optimization Methods for Neural Networkfrom scratch</a>

## Week 3:Hyperparameter tuning, Batch Normalization and Programming Frameworks (tensorflow)

- Tuning process
- Using an appropriate scale to pick hyperparameters
- Hyperparameters tuning in practice: Pandas vs. Caviar
- Normalizing activations in a network
- Fitting Batch Norm into a neural network
- Why does Batch Norm work?
- Batch Norm at test time
- Softmax Regression
- Training a softmax classifier
- Deep learning frameworks
- TensorFlow
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/2.%20Improving%20deep%20Neural%20Networks(Hyperparameter%20tuning%2CRegularization%20and%20Optimization)/w3-Batchnormalization%20and%20Tensorflow/TensorFlow_Tutorial_v3b.ipynb">Neural network using tensorflow</a>

# Course 3: Structuring Machine Learning Projects

## Week 1: ML Strategy (1)

- Why ML Strategy
- Orthogonalization
- Single number evaluation metric
- Satisficing and Optimizing metric
- Train/dev/test distributions
- Size of the dev and test sets
- When to change dev/test sets and metrics
- Why human-level performance?
- Avoidable bias
- Understanding human-level performance,Surpassing human-level performance
- Improving your model performance
- <b>Quiz (case study) </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Structuring%20Machine%20Learning%20Projects/Week%201%20Quiz%20-%20Bird%20recognition%20in%20the%20city%20of%20Peacetopia%20(case%20study).docx"> Bird recognition in the city of Peacetopia (case study)</a>

## Week 2: ML Strategy (2)

- Carrying out error analysis
- Cleaning up incorrectly labeled data
- Build your first system quickly, then iterate
- Training and testing on different distributions
- Bias and Variance with mismatched data distributions
- Addressing data mismatch
- Transfer learning
- Multi-task learning
- What is end-to-end deep learning?
- Whether to use end-to-end deep learning
- <b>Quiz (case study)</b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Structuring%20Machine%20Learning%20Projects/Week%202%20Quiz%20-%20Autonomous%20driving%20(case%20study).docx">Autonomous driving (case study)</a>

# Course 4: Convolutional Neural Networks

## Week 1: Foundations of Convolutional Neural Networks
Learn to implement the foundational layers of CNNs (pooling, convolutions) and to stack them properly in a deep network to solve multi-class image classification problems.

- Computer Vision
- Edge Detection Example
- More Edge Detection
- Padding
- Strided Convolutions
- Convolutions Over Volume
- One Layer of a Convolutional Network
- Simple Convolutional Network Example
- Pooling Layers
- CNN Example
- Why Convolutions?
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Convolution%20Neural%20Networks/w1-Convolution%20model%20_stepby_step/Convolution_model_Step_by_Step_v2a.ipynb">Convolutional Neural Networks: Step by Step (from scratch)</a>

## Week 2:Deep convolutional models: case studies
Learn about the practical tricks and methods used in deep CNNs straight from the research papers.

- Classic Networks
- ResNets
- Why ResNets Work?
- Networks in Networks and 1x1 Convolutions
- Inception Network Motivation
- Inception Network
- Using Open-Source Implementation
- Transfer Learning
- Data Augmentation
- State of Computer Vision
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Convolution%20Neural%20Networks/w2-Keras%20Tutorial%20Happy%20Face%20Detection/Keras_Tutorial_v2a.ipynb">Keras tutorial - Emotion Detection in Images of Faces</a>
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Convolution%20Neural%20Networks/w2-Residual%20Networks/Residual_Networks_v2a.ipynb">Residual Networks</a>

## Week 3:Object detection
Learn how to apply your knowledge of CNNs to one of the toughest but hottest field of computer vision: Object detection.

- Object Localization
- Landmark Detection
- Object Detection
- Convolutional Implementation of Sliding Windows
- Bounding Box Predictions
- Intersection Over Union
- Non-max Suppression
- Anchor Boxes
- YOLO Algorithm
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Convolution%20Neural%20Networks/w3-Car%20Detection%20for%20Autonomous%20Driving/Autonomous_driving_application_Car_detection_v3a.ipynb">Autonomous driving - Car detection</a>

## Week 4 :Special applications: Face recognition & Neural style transfer
Discover how CNNs can be applied to multiple fields, including art generation and face recognition. Implement your own algorithm to generate art and recognize faces!

- What is face recognition?
- One Shot Learning
- Siamese Network
- Triplet Loss
- Face Verification and Binary Classification
- What is neural style transfer?
- What are deep ConvNets learning?
- Cost Function
- Content Cost Function
- Style Cost Function
- 1D and 3D Generalizations
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Convolution%20Neural%20Networks/w4-%20Face%20Verification%20%26Recognition/Face_Recognition_v3a.ipynb">Face Recognition , Face Verification</a>
- <b>Assignment </b> :<a href="https://github.com/richakbee/Deep-Learning-Specialization/blob/main/Convolution%20Neural%20Networks/w4-Art%20Generation%20with%20Neural%20network/Art_Generation_with_Neural_Style_Transfer_v3a%20(1).ipynb">Deep Learning & Art: Neural Style Transfer</a>

